{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['raw_AAL.csv',\n",
       " 'raw_AMC.csv',\n",
       " 'raw_BB.csv',\n",
       " 'raw_BBBY.csv',\n",
       " 'raw_GME.csv',\n",
       " 'raw_PLTR.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "stock_data = os.listdir('../data/dataset/stock_data')\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "with open('../data/models/wordlist/word_list_extended.txt','r') as f:\n",
    "    lmdict = eval(f.read())\n",
    "\n",
    "special_words = {\n",
    "    'crushes': 10,\n",
    "    'beats': 5,\n",
    "    'misses': -5,\n",
    "    'trouble': -10,\n",
    "    'falls': -10,\n",
    "    'exploded' : 4,\n",
    "    'able':2,\n",
    "}\n",
    "\n",
    "for i in lmdict[\"Negative\"]:\n",
    "  special_words[i]=-5\n",
    "\n",
    "for i in lmdict[\"Positive\"]:\n",
    "  special_words[i]=5\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "vader.lexicon.update(special_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification, BertTokenizer\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_path = 'ProsusAI/finbert'\n",
    "MAX_LEN = 512\n",
    "bertmodel = AutoModelForSequenceClassification.from_pretrained(lm_path,cache_dir=None, num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(lm_path)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def FinBert_predict(text):\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "  text,\n",
    "  max_length=MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  padding=False,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "    logits = bertmodel(input_ids, attention_mask).logits\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    return probabilities.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(f'../data/dataset/stock_data/raw_PLTR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.90369976, -1.9084171 ,  0.8328257 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "i = FinBert_predict(raw_df['content'][10])\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.90369976, -1.9084171 ,  0.8328257 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "contents_logits = [ FinBert_predict(content_text).tolist()[0] for content_text in raw_df['content'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.04011860489845276, 0.03856608644127846, 0.9213153123855591],\n",
       " [0.4383324086666107, 0.0328383669257164, 0.5288292169570923],\n",
       " [0.44296303391456604, 0.012332156300544739, 0.5447048544883728]]"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "contents_logits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logits = pd.DataFrame(contents_logits, columns=['neg', 'neu', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 172 entries, 0 to 171\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   neg     172 non-null    float64\n 1   neu     172 non-null    float64\n 2   pos     172 non-null    float64\ndtypes: float64(3)\nmemory usage: 4.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_logits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              neg         neu         pos\n",
       "count  172.000000  172.000000  172.000000\n",
       "mean     0.196786    0.184262    0.618952\n",
       "std      0.277631    0.276012    0.337275\n",
       "min      0.009480    0.006693    0.011943\n",
       "25%      0.030732    0.032978    0.289182\n",
       "50%      0.050187    0.047898    0.792870\n",
       "75%      0.225097    0.172409    0.909400\n",
       "max      0.954582    0.974896    0.956025"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>172.000000</td>\n      <td>172.000000</td>\n      <td>172.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.196786</td>\n      <td>0.184262</td>\n      <td>0.618952</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.277631</td>\n      <td>0.276012</td>\n      <td>0.337275</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.009480</td>\n      <td>0.006693</td>\n      <td>0.011943</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.030732</td>\n      <td>0.032978</td>\n      <td>0.289182</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.050187</td>\n      <td>0.047898</td>\n      <td>0.792870</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.225097</td>\n      <td>0.172409</td>\n      <td>0.909400</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.954582</td>\n      <td>0.974896</td>\n      <td>0.956025</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df_logits.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentiment = [(N/(N+Ne+P), (P-N)/(P+N), math.log((1+P)/(1+N))) for N,Ne,P in df_logits.values]\n",
    "df_sentiment = pd.DataFrame(list_sentiment, columns=['neg1','pos1','pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             neg1        pos1        pos2\n",
       "count  172.000000  172.000000  172.000000\n",
       "mean     0.196786    0.509824    0.299629\n",
       "std      0.277631    0.591573    0.385250\n",
       "min      0.009480   -0.955040   -0.646454\n",
       "25%      0.030731    0.298780    0.072303\n",
       "50%      0.050187    0.831359    0.457036\n",
       "75%      0.225097    0.917926    0.607776\n",
       "max      0.954582    0.956544    0.648025"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neg1</th>\n      <th>pos1</th>\n      <th>pos2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>172.000000</td>\n      <td>172.000000</td>\n      <td>172.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.196786</td>\n      <td>0.509824</td>\n      <td>0.299629</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.277631</td>\n      <td>0.591573</td>\n      <td>0.385250</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.009480</td>\n      <td>-0.955040</td>\n      <td>-0.646454</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.030731</td>\n      <td>0.298780</td>\n      <td>0.072303</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.050187</td>\n      <td>0.831359</td>\n      <td>0.457036</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.225097</td>\n      <td>0.917926</td>\n      <td>0.607776</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.954582</td>\n      <td>0.956544</td>\n      <td>0.648025</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "df_sentiment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.logits.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW\n",
    "\n",
    "df_list = set()\n",
    "for name in stock_data:\n",
    "    raw_df = pd.read_csv(f'../data/dataset/stock_data/{name}')\n",
    "    print(name,\"--------------------------------------\")\n",
    "    print(raw_df.info())\n",
    "    raw_df['Date'] = raw_df['Date'].apply(lambda x :datetime.datetime.strptime(x[:-8],r\"%Y-%m-%dT%H:%M\"))\n",
    "    raw_df.set_index('Date',inplace=True)\n",
    "    raw_df.index = raw_df.index.ceil('H')\n",
    "    a = raw_df.index.value_counts()\n",
    "    print(a[a.values>1])\n",
    "\n",
    "    for col in raw_df.columns:\n",
    "        raw_df[col] = raw_df[col] + ' '\n",
    "    raw_df = raw_df.groupby(level=0).sum()\n",
    "\n",
    "    #applying NLP model!!!!\n",
    "    raw_df = pd.concat([raw_df,])\n",
    "\n",
    "    df_price = yf.download(tickers='PLTR', period='6mo', interval=\"1h\")\n",
    "    df_price.index = df_price.index.tz_convert(None)\n",
    "\n",
    "    df = pd.concat([raw_df.drop(['topic','content'],axis=1),df_price], axis=1)\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    #should subject to each range of data\n",
    "    df_slim = df[df.index>datetime.datetime(2021,3,4,10)]\n",
    "    print(list(map(lambda x : df[x].mask(df[x] != 0, 1).value_counts(), ['topic_comp','content_comp'])))\n",
    "    df_list.append(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "raw_AAL.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     175 non-null    object\n",
      " 1   topic    175 non-null    object\n",
      " 2   content  175 non-null    object\n",
      " 3   url      175 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.6+ KB\n",
      "None\n",
      "2021-04-22 15:00:00    5\n",
      "2021-04-22 12:00:00    4\n",
      "2021-05-10 16:00:00    2\n",
      "2021-05-09 17:00:00    2\n",
      "2021-03-30 17:00:00    2\n",
      "2021-05-12 21:00:00    2\n",
      "2021-04-22 09:00:00    2\n",
      "2021-03-30 21:00:00    2\n",
      "2021-04-22 14:00:00    2\n",
      "2021-06-07 22:00:00    2\n",
      "2021-04-13 13:00:00    2\n",
      "2021-06-03 16:00:00    2\n",
      "2021-03-29 21:00:00    2\n",
      "2021-04-01 22:00:00    2\n",
      "2021-05-11 02:00:00    2\n",
      "2021-04-28 17:00:00    2\n",
      "2021-04-22 13:00:00    2\n",
      "2021-05-07 16:00:00    2\n",
      "2021-04-14 13:00:00    2\n",
      "Name: Date, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    922\n",
      "1.0     94\n",
      "Name: topic_comp, dtype: int64, 0.0    908\n",
      "1.0    108\n",
      "Name: content_comp, dtype: int64]\n",
      "raw_AMC.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     414 non-null    object\n",
      " 1   topic    414 non-null    object\n",
      " 2   content  414 non-null    object\n",
      " 3   url      414 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 13.1+ KB\n",
      "None\n",
      "2021-06-07 20:00:00    38\n",
      "2021-06-07 18:00:00    32\n",
      "2021-06-07 19:00:00    26\n",
      "2021-06-08 18:00:00    23\n",
      "2021-06-07 15:00:00    19\n",
      "2021-06-08 15:00:00    14\n",
      "2021-06-08 11:00:00    13\n",
      "2021-06-08 14:00:00    11\n",
      "2021-06-07 14:00:00    11\n",
      "2021-06-07 21:00:00    11\n",
      "2021-06-03 13:00:00     9\n",
      "2021-06-07 13:00:00     9\n",
      "2021-06-07 23:00:00     8\n",
      "2021-06-07 08:00:00     8\n",
      "2021-06-08 07:00:00     7\n",
      "2021-06-07 06:00:00     7\n",
      "2021-06-04 21:00:00     7\n",
      "2021-06-08 06:00:00     6\n",
      "2021-06-03 18:00:00     6\n",
      "2021-06-08 12:00:00     6\n",
      "2021-06-03 19:00:00     6\n",
      "2021-06-03 17:00:00     6\n",
      "2021-06-07 12:00:00     5\n",
      "2021-06-07 16:00:00     5\n",
      "2021-06-07 10:00:00     5\n",
      "2021-06-03 21:00:00     5\n",
      "2021-06-03 10:00:00     5\n",
      "2021-06-08 16:00:00     5\n",
      "2021-06-08 21:00:00     4\n",
      "2021-06-03 11:00:00     4\n",
      "2021-06-03 22:00:00     4\n",
      "2021-06-03 16:00:00     4\n",
      "2021-06-03 09:00:00     4\n",
      "2021-06-04 13:00:00     3\n",
      "2021-06-08 13:00:00     3\n",
      "2021-06-07 22:00:00     3\n",
      "2021-06-04 06:00:00     3\n",
      "2021-06-03 06:00:00     3\n",
      "2021-06-07 09:00:00     3\n",
      "2021-06-07 11:00:00     3\n",
      "2021-06-04 15:00:00     3\n",
      "2021-06-04 09:00:00     3\n",
      "2021-06-03 15:00:00     3\n",
      "2021-06-04 17:00:00     3\n",
      "2021-06-04 12:00:00     2\n",
      "2021-06-03 08:00:00     2\n",
      "2021-06-05 00:00:00     2\n",
      "2021-06-08 20:00:00     2\n",
      "2021-06-03 14:00:00     2\n",
      "2021-06-04 11:00:00     2\n",
      "2021-06-04 20:00:00     2\n",
      "2021-06-06 10:00:00     2\n",
      "2021-06-03 07:00:00     2\n",
      "2021-06-05 13:00:00     2\n",
      "2021-06-03 00:00:00     2\n",
      "2021-06-04 14:00:00     2\n",
      "2021-06-04 00:00:00     2\n",
      "2021-06-04 19:00:00     2\n",
      "2021-06-08 17:00:00     2\n",
      "Name: Date, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    874\n",
      "1.0     68\n",
      "Name: topic_comp, dtype: int64, 0.0    880\n",
      "1.0     62\n",
      "Name: content_comp, dtype: int64]\n",
      "raw_BB.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246 entries, 0 to 245\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     246 non-null    object\n",
      " 1   topic    246 non-null    object\n",
      " 2   content  246 non-null    object\n",
      " 3   url      246 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 7.8+ KB\n",
      "None\n",
      "2021-06-07 19:00:00    14\n",
      "2021-06-07 20:00:00    11\n",
      "2021-06-07 15:00:00     8\n",
      "2021-06-07 14:00:00     8\n",
      "2021-06-07 23:00:00     6\n",
      "2021-06-07 18:00:00     6\n",
      "2021-06-07 21:00:00     5\n",
      "2021-06-03 18:00:00     5\n",
      "2021-06-08 06:00:00     4\n",
      "2021-06-07 13:00:00     4\n",
      "2021-06-08 18:00:00     3\n",
      "2021-06-08 13:00:00     3\n",
      "2021-06-04 17:00:00     3\n",
      "2021-03-30 22:00:00     3\n",
      "2021-06-03 13:00:00     3\n",
      "2021-06-03 16:00:00     3\n",
      "2021-03-31 14:00:00     3\n",
      "2021-06-03 21:00:00     3\n",
      "2021-06-07 08:00:00     3\n",
      "2021-06-08 17:00:00     3\n",
      "2021-06-08 14:00:00     3\n",
      "2021-06-02 19:00:00     2\n",
      "2021-05-06 12:00:00     2\n",
      "2021-06-03 19:00:00     2\n",
      "2021-03-31 05:00:00     2\n",
      "2021-03-25 13:00:00     2\n",
      "2021-06-02 06:00:00     2\n",
      "2021-06-07 06:00:00     2\n",
      "2021-05-26 19:00:00     2\n",
      "2021-06-08 15:00:00     2\n",
      "2021-03-09 17:00:00     2\n",
      "2021-06-03 10:00:00     2\n",
      "2021-06-08 11:00:00     2\n",
      "2021-06-08 16:00:00     2\n",
      "2021-06-03 17:00:00     2\n",
      "2021-06-01 11:00:00     2\n",
      "Name: Date, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    912\n",
      "1.0    101\n",
      "Name: topic_comp, dtype: int64, 0.0    905\n",
      "1.0    108\n",
      "Name: content_comp, dtype: int64]\n",
      "raw_BBBY.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     218 non-null    object\n",
      " 1   topic    218 non-null    object\n",
      " 2   content  218 non-null    object\n",
      " 3   url      218 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.9+ KB\n",
      "None\n",
      "2021-06-07 18:00:00    12\n",
      "2021-06-07 06:00:00     7\n",
      "2021-06-07 19:00:00     5\n",
      "2021-06-07 20:00:00     5\n",
      "2021-06-07 15:00:00     4\n",
      "2021-02-02 17:00:00     4\n",
      "2021-06-07 14:00:00     3\n",
      "2021-06-03 18:00:00     3\n",
      "2021-02-01 17:00:00     3\n",
      "2021-06-03 16:00:00     3\n",
      "2021-06-03 13:00:00     3\n",
      "2021-04-14 14:00:00     2\n",
      "2021-01-29 18:00:00     2\n",
      "2021-06-02 22:00:00     2\n",
      "2021-06-08 15:00:00     2\n",
      "2021-04-19 12:00:00     2\n",
      "2021-04-14 11:00:00     2\n",
      "2021-03-29 12:00:00     2\n",
      "2021-06-02 18:00:00     2\n",
      "2021-03-29 13:00:00     2\n",
      "2021-05-28 21:00:00     2\n",
      "2021-06-08 11:00:00     2\n",
      "2021-04-14 18:00:00     2\n",
      "2021-04-12 21:00:00     2\n",
      "2021-06-07 13:00:00     2\n",
      "2021-01-29 22:00:00     2\n",
      "2021-06-02 19:00:00     2\n",
      "2021-06-07 12:00:00     2\n",
      "2021-02-01 20:00:00     2\n",
      "2021-06-08 14:00:00     2\n",
      "2021-06-03 10:00:00     2\n",
      "2021-04-15 11:00:00     2\n",
      "2021-02-01 21:00:00     2\n",
      "2021-04-07 17:00:00     2\n",
      "2021-06-03 14:00:00     2\n",
      "2021-04-14 09:00:00     2\n",
      "Name: Date, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    922\n",
      "1.0     95\n",
      "Name: topic_comp, dtype: int64, 0.0    906\n",
      "1.0    111\n",
      "Name: content_comp, dtype: int64]\n",
      "raw_GME.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 410 entries, 0 to 409\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     410 non-null    object\n",
      " 1   topic    410 non-null    object\n",
      " 2   content  410 non-null    object\n",
      " 3   url      410 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 12.9+ KB\n",
      "None\n",
      "2021-06-09 21:00:00    10\n",
      "2021-06-04 17:00:00     9\n",
      "2021-06-10 21:00:00     8\n",
      "2021-06-04 21:00:00     7\n",
      "2021-06-11 23:00:00     7\n",
      "                       ..\n",
      "2021-05-28 18:00:00     2\n",
      "2021-06-08 18:00:00     2\n",
      "2021-05-27 21:00:00     2\n",
      "2021-06-11 12:00:00     2\n",
      "2021-06-02 19:00:00     2\n",
      "Name: Date, Length: 93, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    923\n",
      "1.0    143\n",
      "Name: topic_comp, dtype: int64, 0.0    940\n",
      "1.0    126\n",
      "Name: content_comp, dtype: int64]\n",
      "raw_PLTR.csv --------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172 entries, 0 to 171\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Date     172 non-null    object\n",
      " 1   topic    172 non-null    object\n",
      " 2   content  172 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.2+ KB\n",
      "None\n",
      "2021-05-11 12:00:00    4\n",
      "2021-05-11 21:00:00    3\n",
      "2021-05-11 16:00:00    3\n",
      "2021-05-11 11:00:00    3\n",
      "2021-05-11 15:00:00    3\n",
      "2021-05-11 13:00:00    3\n",
      "2021-06-04 21:00:00    2\n",
      "2021-04-08 14:00:00    2\n",
      "2021-05-21 18:00:00    2\n",
      "2021-05-24 11:00:00    2\n",
      "2021-04-05 15:00:00    2\n",
      "2021-04-29 22:00:00    2\n",
      "2021-05-11 18:00:00    2\n",
      "2021-05-12 13:00:00    2\n",
      "2021-05-06 11:00:00    2\n",
      "2021-03-25 15:00:00    2\n",
      "2021-05-26 19:00:00    2\n",
      "Name: Date, dtype: int64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[0.0    925\n",
      "1.0     88\n",
      "Name: topic_comp, dtype: int64, 0.0    931\n",
      "1.0     82\n",
      "Name: content_comp, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "#OLD\n",
    "df_list = set()\n",
    "for name in stock_data:\n",
    "    raw_df = pd.read_csv(f'../data/dataset/stock_data/{name}')\n",
    "    print(name,\"--------------------------------------\")\n",
    "    print(raw_df.info())\n",
    "    raw_df['Date'] = raw_df['Date'].apply(lambda x :datetime.datetime.strptime(x[:-8],r\"%Y-%m-%dT%H:%M\"))\n",
    "    raw_df.set_index('Date',inplace=True)\n",
    "    raw_df.index = raw_df.index.ceil('H')\n",
    "    a = raw_df.index.value_counts()\n",
    "    print(a[a.values>1])\n",
    "\n",
    "    for col in raw_df.columns:\n",
    "        raw_df[col] = raw_df[col] + ' '\n",
    "    raw_df = raw_df.groupby(level=0).sum()\n",
    "\n",
    "    #applying NLP model!!!!\n",
    "    raw_df['topic_comp'] = raw_df['topic'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
    "    raw_df['content_comp'] = raw_df['content'].apply(lambda x: vader.polarity_scores(x)['compound'])\n",
    "    raw_df['topic_logpos'] = raw_df['topic'].apply(log_pos)\n",
    "    raw_df['content_logpos'] = raw_df['content'].apply(log_pos)\n",
    "\n",
    "    df_price = yf.download(tickers='PLTR', period='6mo', interval=\"1h\")\n",
    "    df_price.index = df_price.index.tz_convert(None)\n",
    "\n",
    "    df = pd.concat([raw_df.drop(['topic','content'],axis=1),df_price], axis=1)\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    #should subject to each range of data\n",
    "    df_slim = df[df.index>datetime.datetime(2021,3,4,10)]\n",
    "    print(list(map(lambda x : df[x].mask(df[x] != 0, 1).value_counts(), ['topic_comp','content_comp'])))\n",
    "    df_list.append(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'DataFrame' objects are mutable, thus they cannot be hashed",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-98648f658db5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1786\u001b[0m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}